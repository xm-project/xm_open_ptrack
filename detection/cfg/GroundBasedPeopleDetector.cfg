#! /usr/bin/env python

# Declare parameters that control haar-based people detection

PACKAGE='detection'

from dynamic_reconfigure.parameter_generator_catkin import *

gen = ParameterGenerator()

##############################################
## Ground-based people detection parameters ##
##############################################
# Threshold on the ratio of valid points needed for ground estimation:
gen.add("valid_points_threshold", double_t, 0, "Minimum ratio of valid point cloud points", 0.3, 0.0, 1.0)
# Minimum detection confidence for hog+svm algorithm on rgb or ir images:
gen.add("ground_based_people_detection_min_confidence", double_t, 0, "Minimum detection confidence (hog+svm)", -1.75, -10.0, 10.0)
# Minimum person height:
gen.add("minimum_person_height", double_t, 0, "Minimum person height", 1.0, 0.0, 2.0)
# Maximum person height:
gen.add("maximum_person_height", double_t, 0, "Maximum person height", 2.3, 1.0, 4.0)
# Threshold on distance from the sensor:
gen.add("max_distance", double_t, 0, "Threshold on distance from the sensor", 50.0, 1.0, 50.0)
# Point cloud downsampling factor:
sampling_factor_enum = gen.enum([ gen.const("1",  int_t, 1, "1"),
				                  gen.const("2",  int_t, 2, "2"),
				                  gen.const("4",  int_t, 4, "4"),
								  gen.const("8",  int_t, 8, "8")],
			                      "An enum to set sampling_factor")
gen.add("sampling_factor", int_t, 0, "Point cloud downsampling factor", 4, 1, 8, edit_method=sampling_factor_enum)
# Flag stating if classifiers based on RGB image should be used or not:
gen.add("use_rgb", bool_t, 0, "Flag stating if classifiers based on RGB image should be used or not", True)
# Threshold on image luminance. If luminance is over this threshold, classifiers on RGB image are also used:
gen.add("minimum_luminance", int_t, 0, "Threshold on image luminance. If luminance is over this threshold, classifiers on RGB image are also used", 120, 0, 255)
# If true, sensor tilt angle wrt ground plane is compensated to improve people detection:
gen.add("sensor_tilt_compensation", bool_t, 0, "If true, sensor tilt angle wrt ground plane is compensated to improve people detection", True)
# Minimum distance between two persons:
gen.add("heads_minimum_distance", double_t, 0, "Minimum distance between two persons", 0.3, 0.0, 1.0)
# Voxel size used to downsample the point cloud (lower: detection slower but more precise; higher: detection faster but less precise):
gen.add("voxel_size", double_t, 0, "Voxel size used to downsample the point cloud", 0.06, 0.01, 0.1)

############################
## Background subtraction ##
############################
# Flag enabling/disabling background subtraction:
gen.add("background_subtraction", bool_t, 0, "Flag enabling/disabling background subtraction", False)
# Resolution of the octree representing the background:
gen.add("background_resolution", double_t, 0, "Resolution of the octree representing the background", 0.3, 0.01, 1.0)
# Seconds to use to learn the background:
gen.add("background_seconds", double_t, 0, "Seconds to use to learn the background", 3.0, 0.2, 10.0)

#######################
## Ground estimation ##
#######################
# Flag that locks the ground plane update:
gen.add("lock_ground", bool_t, 0, "# Flag that locks the ground plane update", False)

#####################
## For SwissRanger ##
#####################
# Threshold on SwissRanger depth confidence:
gen.add("sr_conf_threshold", int_t, 0, "Threshold on SwissRanger depth confidence", 180, 0, 255)

# First string value is node name, used only for generating documentation
# Second string value ("GroundBasedPeopleDetector") is name of class and generated
#    .h file, with "Config" added, so class GroundBasedPeopleDetectorConfig
exit(gen.generate(PACKAGE, "detection", "GroundBasedPeopleDetector"))
